{
  "conversations": [
    {
      "config": {
        "prompt": "default",
        "context_length": 6,
        "model": "gpt-3.5-turbo",
        "stream": true,
        "temperature": 0,
        "max_tokens": 1024
      },
      "context": [
        {
          "question": "hello",
          "answer": ""
        },
        {
          "question": "???",
          "answer": ""
        },
        {
          "question": "hell",
          "answer": ""
        },
        {
          "question": "he",
          "answer": ""
        },
        {
          "question": "he",
          "answer": ""
        },
        {
          "question": "hell",
          "answer": ""
        }
      ]
    }
  ],
  "last_idx": 0
}
